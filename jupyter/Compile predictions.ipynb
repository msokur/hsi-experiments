{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "competent-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir) \n",
    "sys.path.insert(0, os.path.join(parentdir, 'utils') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "municipal-print",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: psutil in /home/sc.uni-leipzig.de/mi186veva/.local/lib/python3.8/site-packages (5.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "approximate-empty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: colorama in /home/sc.uni-leipzig.de/mi186veva/.local/lib/python3.8/site-packages (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hybrid-visiting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paths from config ['/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/utils', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/data_utils/data_loaders', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/models', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/trainers', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/data_utils', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/utils', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/jupyter', '/software/jupyterlab/opt/anaconda3/envs/tensorflow/lib/python38.zip', '/software/jupyterlab/opt/anaconda3/envs/tensorflow/lib/python3.8', '/software/jupyterlab/opt/anaconda3/envs/tensorflow/lib/python3.8/lib-dynload', '', '/home/sc.uni-leipzig.de/mi186veva/.local/lib/python3.8/site-packages', '/software/jupyterlab/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages']\n",
      "FILES_TO_COPY ['/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/utils.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/cross_validation.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/callbacks.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/config.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/provider.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/test.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/validator.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/untitled.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/data_utils/hypercube_data.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/data_utils/augmentator.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/data_utils/background_detection.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/data_utils/preprocessor.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/data_utils/generator.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/models/model_3d.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/models/model.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/models/keras_tuner_model.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/models/keras_tuner_models_with_ones.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/data_utils/data_loaders/data_loader_easy.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/data_utils/data_loaders/data_loader_mat.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/data_utils/data_loaders/data_loader_base.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/data_utils/data_loaders/data_loader_mat_colon.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/data_utils/data_loaders/data_loader_mat_brain.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/trainers/trainer_base.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/trainers/trainer_tuner.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/trainers/trainer_easy.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/trainers/test_tuner.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/trainers/trainer_easy_several_outputs.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/utils/check_preprocessor.py', '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/utils/tf_metrics.py']\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import itertools as it, glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "standing-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glob_multiple_file_types(path, *patterns):\n",
    "    return list(it.chain.from_iterable(glob.iglob(os.path.join(path, pattern)) for pattern in patterns))\n",
    "\n",
    "\n",
    "def round_to_the_nearest_even_int(number, nearest_int=config.WRITE_CHECKPOINT_EVERY_Xth_STEP):\n",
    "    return int(int(number / nearest_int) * nearest_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "orange-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history(model_path):\n",
    "    history_paths = glob_multiple_file_types(model_path, '.*.npy', '*.npy')\n",
    "    #print(history_paths)\n",
    "    if len(history_paths) == 0:\n",
    "        print('Error! No history files were found!')\n",
    "        #raise ValueError('Error! No history files were found!')\n",
    "        return {}, model_path\n",
    "    if len(history_paths) > 1:\n",
    "        print(f'Error! Too many .npy files were found in {model_path}!')\n",
    "        return {}, model_path\n",
    "        #raise ValueError(f'Error! Too many .npy files were found in {model_path}!')\n",
    "\n",
    "    history_path = history_paths[0]\n",
    "    history = np.load(history_path, allow_pickle=True)\n",
    "    #print(history)\n",
    "    if len(history.shape) == 0:\n",
    "        history = history.item()\n",
    "    #print(history)\n",
    "    return history, history_path\n",
    "\n",
    "def get_best_checkpoint_from_valid(results_file, nearest_int=config.WRITE_CHECKPOINT_EVERY_Xth_STEP):\n",
    "    model_paths = []\n",
    "    best_checkpoints = []\n",
    "\n",
    "    with open(results_file, newline='') as csvfile:\n",
    "        report_reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        for row in tqdm(report_reader):\n",
    "            model_path = row[5]\n",
    "            if 'LOCAL' in config.MODE:\n",
    "                model_path = row[5].split('hsi-experiments')[-1][1:]\n",
    "\n",
    "            model_paths.append(model_path)\n",
    "\n",
    "            history, history_path = get_history(model_path)\n",
    "            if not bool(history):\n",
    "                print(f'Attention!! {history_path} is empty!!!')\n",
    "                continue\n",
    "            #best_checkpoint = np.argmin(history[config.HISTORY_ARGMIN])\n",
    "            best_checkpoint = np.argmax(history['val_accuracy'])\n",
    "            \n",
    "            best_checkpoints.append(best_checkpoint)\n",
    "\n",
    "    if len(best_checkpoints) == 0:\n",
    "        return -1, best_checkpoints, model_paths\n",
    "\n",
    "    best_checkpoint = round_to_the_nearest_even_int(np.median(best_checkpoints), nearest_int = nearest_int)\n",
    "\n",
    "    return best_checkpoint, best_checkpoints, model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "protective-battlefield",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:00, 690.26it/s]\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint, best_checkpoints, model_paths = get_best_checkpoint_from_valid('/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/logs/CV_3d_inception/CV_3d_inception_stats_07.12.2021-00_01_56.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "polyphonic-pulse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([39,\n",
       "  39,\n",
       "  39,\n",
       "  39,\n",
       "  37,\n",
       "  37,\n",
       "  37,\n",
       "  37,\n",
       "  35,\n",
       "  35,\n",
       "  35,\n",
       "  35,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  39,\n",
       "  39,\n",
       "  39,\n",
       "  36,\n",
       "  36,\n",
       "  36,\n",
       "  36,\n",
       "  36,\n",
       "  36,\n",
       "  36,\n",
       "  36,\n",
       "  37,\n",
       "  37,\n",
       "  37,\n",
       "  37,\n",
       "  39,\n",
       "  39,\n",
       "  39,\n",
       "  39,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  36,\n",
       "  36,\n",
       "  36,\n",
       "  36,\n",
       "  29,\n",
       "  29,\n",
       "  29,\n",
       "  29,\n",
       "  24,\n",
       "  24,\n",
       "  24,\n",
       "  24],\n",
       " 36)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoints, best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "informative-fourth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([39,\n",
       "  39,\n",
       "  39,\n",
       "  39,\n",
       "  37,\n",
       "  37,\n",
       "  37,\n",
       "  37,\n",
       "  35,\n",
       "  35,\n",
       "  35,\n",
       "  35,\n",
       "  25,\n",
       "  25,\n",
       "  25,\n",
       "  25,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  39,\n",
       "  39,\n",
       "  39,\n",
       "  35,\n",
       "  35,\n",
       "  35,\n",
       "  35,\n",
       "  36,\n",
       "  36,\n",
       "  36,\n",
       "  36,\n",
       "  37,\n",
       "  37,\n",
       "  37,\n",
       "  37,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  36,\n",
       "  36,\n",
       "  36,\n",
       "  36,\n",
       "  29,\n",
       "  29,\n",
       "  29,\n",
       "  29,\n",
       "  24,\n",
       "  24,\n",
       "  24,\n",
       "  24],\n",
       " 36)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoints, best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "loaded-caution",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [11:08, 11.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 56\n"
     ]
    }
   ],
   "source": [
    "gt_compiled = []\n",
    "predictions_compiled = []\n",
    "prefix = '/home/sc.uni-leipzig.de/mi186veva/hsi-experiments/test/'\n",
    "\n",
    "folder = 'CV_3d_inception'\n",
    "\n",
    "for pat_number, checkpoint in tqdm(enumerate(best_checkpoints)):\n",
    "    checkpoint = round_to_the_nearest_even_int(checkpoint, nearest_int = 2)\n",
    "    \n",
    "    pred = np.load(os.path.join(prefix, folder, f'cp-{checkpoint:04d}', 'predictions_by_patient.npy'), allow_pickle=True)\n",
    "    gt = np.load(os.path.join(prefix, folder, f'cp-{checkpoint:04d}', 'gt_by_patient.npy'), allow_pickle=True)\n",
    "    \n",
    "    gt_compiled.append(gt[pat_number])\n",
    "    predictions_compiled.append(pred[pat_number])\n",
    "    \n",
    "print(len(gt_compiled), len(predictions_compiled))\n",
    "\n",
    "save_path = os.path.join(prefix, folder, 'compiled')\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "    \n",
    "np.save(os.path.join(save_path, 'predictions_by_patient'), predictions_compiled)\n",
    "np.save(os.path.join(save_path, 'gt_by_patient'), gt_compiled)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "monetary-delta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_to_the_nearest_even_int(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "broad-token",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.round(5 / 2) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "painted-malawi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(55 / 50) * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "banned-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "a = [[\"l2_norm\", \"svn\"],[\"with_sample_weights\", \"without_sample_weights\"],[\"exclude_1\", \"exclude_4\"], [\"every_third\", \"all\"]]\n",
    "g = list(itertools.product(*a))\n",
    "g_ = pd.DataFrame(g, columns=[\"norm\", \"sample_weights\", \"exclude\", \"e3_all\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "under-packet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm</th>\n",
       "      <th>sample_weights</th>\n",
       "      <th>exclude</th>\n",
       "      <th>e3_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2_norm</td>\n",
       "      <td>with_sample_weights</td>\n",
       "      <td>exclude_1</td>\n",
       "      <td>every_third</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2_norm</td>\n",
       "      <td>with_sample_weights</td>\n",
       "      <td>exclude_1</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2_norm</td>\n",
       "      <td>with_sample_weights</td>\n",
       "      <td>exclude_4</td>\n",
       "      <td>every_third</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2_norm</td>\n",
       "      <td>with_sample_weights</td>\n",
       "      <td>exclude_4</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l2_norm</td>\n",
       "      <td>without_sample_weights</td>\n",
       "      <td>exclude_1</td>\n",
       "      <td>every_third</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l2_norm</td>\n",
       "      <td>without_sample_weights</td>\n",
       "      <td>exclude_1</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l2_norm</td>\n",
       "      <td>without_sample_weights</td>\n",
       "      <td>exclude_4</td>\n",
       "      <td>every_third</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>l2_norm</td>\n",
       "      <td>without_sample_weights</td>\n",
       "      <td>exclude_4</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svn</td>\n",
       "      <td>with_sample_weights</td>\n",
       "      <td>exclude_1</td>\n",
       "      <td>every_third</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svn</td>\n",
       "      <td>with_sample_weights</td>\n",
       "      <td>exclude_1</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>svn</td>\n",
       "      <td>with_sample_weights</td>\n",
       "      <td>exclude_4</td>\n",
       "      <td>every_third</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svn</td>\n",
       "      <td>with_sample_weights</td>\n",
       "      <td>exclude_4</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svn</td>\n",
       "      <td>without_sample_weights</td>\n",
       "      <td>exclude_1</td>\n",
       "      <td>every_third</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>svn</td>\n",
       "      <td>without_sample_weights</td>\n",
       "      <td>exclude_1</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>svn</td>\n",
       "      <td>without_sample_weights</td>\n",
       "      <td>exclude_4</td>\n",
       "      <td>every_third</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>svn</td>\n",
       "      <td>without_sample_weights</td>\n",
       "      <td>exclude_4</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       norm          sample_weights    exclude       e3_all\n",
       "0   l2_norm     with_sample_weights  exclude_1  every_third\n",
       "1   l2_norm     with_sample_weights  exclude_1          all\n",
       "2   l2_norm     with_sample_weights  exclude_4  every_third\n",
       "3   l2_norm     with_sample_weights  exclude_4          all\n",
       "4   l2_norm  without_sample_weights  exclude_1  every_third\n",
       "5   l2_norm  without_sample_weights  exclude_1          all\n",
       "6   l2_norm  without_sample_weights  exclude_4  every_third\n",
       "7   l2_norm  without_sample_weights  exclude_4          all\n",
       "8       svn     with_sample_weights  exclude_1  every_third\n",
       "9       svn     with_sample_weights  exclude_1          all\n",
       "10      svn     with_sample_weights  exclude_4  every_third\n",
       "11      svn     with_sample_weights  exclude_4          all\n",
       "12      svn  without_sample_weights  exclude_1  every_third\n",
       "13      svn  without_sample_weights  exclude_1          all\n",
       "14      svn  without_sample_weights  exclude_4  every_third\n",
       "15      svn  without_sample_weights  exclude_4          all"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "display(g_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python + Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
